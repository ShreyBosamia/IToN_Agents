# ADR-004: Query Generator Output Contract + Repair Retry + Category Hints

**Status:** Accepted

## Context

The Query Generator is the first step of the In Time of Need pipeline. Downstream stages (search, scraping, extraction) depend on receiving **exactly 10** high-quality, locality-specific search queries.

In practice, LLM output can drift from the intended format (extra commentary, numbered lists, fewer than 10 items, duplicates). The previous implementation attempted to “normalize” output and would **pad** results when fewer than 10 unique queries were produced, which can reduce downstream search coverage and hide upstream failures.

We also observed that a single generic prompt under-specifies category-specific language (e.g., FOOD_BANK vs SHELTER), leading to less relevant queries.

## Decision

We will harden the Query Generator with three changes:

1. **Structured output contract:** The model must return **valid JSON only** in the form of a JSON array of **exactly 10 distinct strings**. This improves parsing reliability and reduces format drift.
2. **Repair retry instead of padding:** If parsing or validation fails (invalid JSON, not exactly 10 queries, duplicates), the system performs **one repair retry** with a strict correction instruction. If the repair attempt still fails, we throw an error instead of silently padding duplicates.
3. **Category-specific guidance:** Maintain a small lookup of category hints (synonyms/phrasing) injected into the system prompt to improve relevance per category.

Note: Even though the model output contract is JSON, we will continue to save queries as a plain text file (one query per line) for human readability and simple downstream consumption.

## Decision Drivers

- Reliability: make model output predictable and parseable.
- Correctness: guarantee 10 distinct queries or fail fast.
- Relevance: improve category-specific query phrasing without over-complicating the prompt.
- Maintainability: keep the approach simple and easy to extend with new categories.

## Options Considered

### A) Plain-text “10 lines” output (previous)

- Pros: easy for humans to read; downstream already expects line-delimited text.
- Cons: higher chance of formatting drift (numbering, headings, commentary); harder to parse robustly.

### B) JSON array output contract (chosen)

- Pros: much more reliable parsing; simpler validation; reduces normalization hacks.
- Cons: requires prompt + parser changes; must guard against accidental markdown fences.

### C) Padding duplicates when fewer than 10 (previous)

- Pros: always returns 10 lines.
- Cons: silently reduces search diversity; hides upstream failures.

### D) Repair retry on invalid output (chosen)

- Pros: usually fixes drift with one additional call; preserves distinctness.
- Cons: slightly higher cost in failure cases; still needs a hard failure path.

### E) Category-agnostic prompt only (previous)

- Pros: simpler prompt.
- Cons: weaker relevance across categories.

### F) Category hint map injected into prompt (chosen)

- Pros: improves relevance with minimal complexity; easy to extend.
- Cons: requires maintaining a small taxonomy of hints.

## Consequences

### Positive

- Query generation becomes deterministic from the caller’s perspective: either **exactly 10 distinct queries** are returned or an error is raised.
- Reduced downstream noise from duplicates and format drift.
- Better relevance per category via targeted synonyms and phrases.

### Negative

- Occasional extra OpenAI call (repair retry) when output fails validation.
- Slightly more prompt and parsing logic to maintain.

## Implementation Notes

- Enforce JSON-only output in the system prompt and few-shot example.
- Parse JSON first; fall back to line parsing only as a safety net.
- Validate:
  - array length is exactly 10
  - every entry is a non-empty string
  - no duplicates
- On validation failure, perform one repair retry; then throw.
- Category hints are stored in a small mapping and appended to the system prompt for the provided category.

## References

- OpenAI Chat Completions API (structured output best practices): https://platform.openai.com/docs
- Project module: src/agents/queryGenerator.ts
